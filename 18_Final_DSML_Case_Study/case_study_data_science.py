# -*- coding: utf-8 -*-
"""case_study_Data_science.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14tCa6Yf_93No-lL2kFZL-2qA-_1xtmPE

## Data Science Case Study
"""

#---------------------------------------------------------------------------------------------
import numpy as np
import pandas as pd

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns


#---------------------------------------------------------------------------------------------
df = pd.read_csv('city_day.csv')
df.head()


#---------------------------------------------------------------------------------------------
df.tail()

#---------------------------------------------------------------------------------------------
df.shape
#in dataset 29531 rows and 16 column(features)


#---------------------------------------------------------------------------------------------
df.describe()
#count having sum of NotNaN values

#---------------------------------------------------------------------------------------------
#count missing(NaN or Others) value in data set
df.isna().sum()

#---------------------------------------------------------------------------------------------
#you can also write 
df.isnull().sum()


#---------------------------------------------------------------------------------------------
#how to find, how many percentage(%) missing value
len(df)

missing_Value_Percentage = df.isnull().sum()/len(df)
missing_Value_Percentage

#---------------------------------------------------------------------------------------------
type(missing_Value_Percentage)


#---------------------------------------------------------------------------------------------
#convert into dataframe
missing_Value_Percentage_dataframe = pd.DataFrame(missing_Value_Percentage)
missing_Value_Percentage_dataframe

type(missing_Value_Percentage_dataframe)


#---------------------------------------------------------------------------------------------
#give name of our data frame percentage column
missing_Value_Percentage_dataframe.columns=['proposition']
missing_Value_Percentage_dataframe


#---------------------------------------------------------------------------------------------
missing_Value_Percentage_dataframe = missing_Value_Percentage_dataframe.sort_values(by='proposition',ascending=False)
missing_Value_Percentage_dataframe


#---------------------------------------------------------------------------------------------
df['City'].unique()

#i print which city and there AQI(air quality index) of mean 
# i put into same city in one group
# there all AQI mean
# i print city wise mean of AQI 
group = pd.DataFrame(df.groupby(['City'])[['AQI']].mean())
group


#---------------------------------------------------------------------------------------------

#print top 10 mean of AQI of each city in descending order
group = group.sort_values(by='AQI',ascending=False).head(10)
group


#---------------------------------------------------------------------------------------------
#now city become index
group = group.reset_index('City')
group


#---------------------------------------------------------------------------------------------
#now generate graph
#make sizing
plt.figure(figsize=(13,8))
#use seborn 
sns.barplot(data=group,x='AQI',y='City',orient='h')

plt.figure(figsize=(13,8))
sns.barplot(data=group,x='City',y='AQI',orient='v')


#---------------------------------------------------------------------------------------------
df.info()
#see our City, AQI_Bucket and Date type is Object

#change type of Date object to date-time
df['Date'] = pd.to_datetime(df['Date'],format='%Y-%m-%d') 
# see %Y is capital

df.info()
#see our Date column type is 'datetime64[ns]'

#---------------------------------------------------------------------------------------------
#add separate column as Month and Year
#see proper syntex df.Date.dt.month.astype(str) first df and second dt
df['month']=df.Date.dt.month.astype(str)
df['year']=df.Date.dt.year.astype(str)


df.head()

#---------------------------------------------------------------------------------------------
#line plot analysis for amount of particulate matter and gases  over the years
cols=['PM2.5','PM10','NO2','NOx','NH3',
      'CO','SO2','O3','Benzene','Toluene','Xylene']

#enumerate give you index of each column
for i,col  in enumerate(cols):
  print(i,"----",col)


#---------------------------------------------------------------------------------------------
#drow line plot
#fig.add_subplot(row,column,start from 1)
#in our case 'i' start from 0
fig=plt.figure(figsize=(10,13))
for i,col  in enumerate(cols):
    fig.add_subplot(6,2,i+1)
    sns.lineplot(x='year',y=col,data=df)


#---------------------------------------------------------------------------------------------
#with dropna in data = df.dropna()
#drow line plot
#fig.add_subplot(row,column,start from 1)
#in our case 'i' start from 0
fig=plt.figure(figsize=(10,13))
for i,col  in enumerate(cols):
    fig.add_subplot(6,2,i+1)
    sns.lineplot(x='year',y=col,data=df.dropna())


#---------------------------------------------------------------------------------------------
#distribuiton of various gases and particulate in air
#make histogram graph

cols=['PM2.5','PM10','NO2','NOx','NH3',
      'CO','SO2','O3','Benzene','Toluene','Xylene']

fig=plt.figure(figsize=(12,20))

for i,col in enumerate(cols):
    fig.add_subplot(6,2,i+1)
    plt.hist(df[col].dropna(),bins=10,edgecolor='yellow')
    plt.xlabel(col)
    plt.ylabel('Count')

#i put df[col] bcz i want to make histogram of this columns
#see i put df[col].dropna() because some missing value in there
# see what is histogram properly in google


#---------------------------------------------------------------------------------------------
#correlation analysis
#correlation gives you how value correlate each other

plt.figure(figsize=(15,15))

#mask=np.triu(df.corr(method='pearson'))
sns.heatmap(df.corr(),
            annot=True,fmt='0.1f',
            cmap='Blues')
plt.title('Correlation Analysis')


#---------------------------------------------------------------------------------------------

#in city Ari quality index greter then 500 how many times
df['City'][df['AQI']>=500].value_counts()



#---------------------------------------------------------------------------------------------
x=df[df['City']=='Ahmedabad']
x


#---------------------------------------------------------------------------------------------
#plotting the average AQI over the years for top 5 cities which have AQI greater than 500

cols=['Ahmedabad','Delhi','Patna','Gurugram','Lucknow']

for col in cols:
    plt.figure(figsize=(12,8))
    #selecting data pertaining to the selected city
    x=df[df['City']==col]
    sns.barplot(x='year',y='AQI',data=x)
    plt.title(col)

#---------------------------------------------------------------------------------------------
x=df.groupby('City')['CO'].sum().sort_values(ascending=False)
x.reset_index('City')


#---------------------------------------------------------------------------------------------
#try to explode=[1,0,0,0,0,0,0,0]
explode=[0.4,0,0,0,0,0,0,0]
plt.figure(figsize=(10,8))

'''grouping above columns by cities and 
taking 8 cities which have the highest sum'''

x=df.groupby('City')['CO'].sum().sort_values(ascending=False)
x.reset_index('City')
x[:8].plot.pie(shadow=True,autopct='%1.1f%%',
                explode=explode,
                wedgeprops={'edgecolor':'black','linewidth':0.3}
                )


#---------------------------------------------------------------------------------------------
cols=['PM2.5','PM10','CO','NO','NO2']

cmap=plt.get_cmap('Spectral')
explode=[0.2,0,0,0,0,0,0,0]

for col in cols:
    plt.figure(figsize=(8,6))
    
    '''grouping above columns by cities and 
    taking 8 cities which have the highest sum'''
    
    x=df.groupby('City')[col].sum().sort_values(ascending=False)
    x.reset_index('City')
    x[:8].plot.pie(shadow=True,autopct='%1.1f%%',
                   explode=explode,
                   wedgeprops={'edgecolor':'black','linewidth':0.3}
                   )


#---------------------------------------------------------------------------------------------
x=df[(df['City']=='Ahmedabad') & (df['year']=='2018')]
x
#see all data in year 2018


#---------------------------------------------------------------------------------------------
#from above bar plots we see that for Ahmedabad highest avearge AQI is for the year 2018 so let's 
#plot the monthly distribution of AQI for Ahmedabad for the year 2018

x=df[(df['City']=='Ahmedabad') & (df['year']=='2018')]

plt.figure(figsize=(10,8))
sns.barplot(x='month',y='AQI',data=x)

#---------------------------------------------------------------------------------------------

cols=['PM2.5','PM10','NO2','NOx','NH3',
      'CO','SO2','O3','Benzene','Toluene','Xylene']

fig=plt.figure(figsize=(10,18))

for i,col in enumerate(cols):
    fig.add_subplot(6,2,i+1)
    sns.scatterplot(x=col,y='AQI',data=df,s=8)
    plt.xlabel(col)
    plt.ylabel('AQI')

#plt.figure(figsize=(2.3,1.5))
#sns.scatterplot(x='Benzene',y='Toluene',data=df,s=8)
    
    
#---------------------------------------------------------------------------------------------